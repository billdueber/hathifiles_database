#!/usr/bin/env ruby

# This is the preferred, date-independent way of bringing the database
# completely up to date with the hathifiles inventory using the hathifiles.hf_log
# database table.

$LOAD_PATH.unshift "../lib"

require "cgi"
require "dotenv"
require "logger"
require "pathname"
require "push_metrics"
require "tmpdir"

require "hathifiles_database"

envfile = Pathname.new(__dir__).parent + ".env"
Dotenv.load(envfile)

# This is the "right" way to do the connection if there is a chance the password
# will contain non-URI-safe characters (as is likely to be the case).
# We are careful not to let the URI::InvalidURIError backtrace get logged since
# it can disclose the password.
# In future we should have a HathifilesDatabase::DB::Connection implementation that
# passes the individual ENV bits to Sequel, then we can deprecate the use of a connection
# string/URI.

# See https://github.com/hathitrust/rights_database/blob/main/lib/rights_database/db.rb
# for a representative implementation.

mysql_user = ENV["HATHIFILES_MYSQL_USER"]
mysql_password = CGI.escape ENV["HATHIFILES_MYSQL_PASSWORD"]
mysql_host = ENV["HATHIFILES_MYSQL_HOST"]
mysql_database = ENV["HATHIFILES_MYSQL_DATABASE"]
connection_uri = "mysql2://#{mysql_user}:#{mysql_password}@#{mysql_host}/#{mysql_database}"

begin
  connection = HathifilesDatabase.new(connection_uri)
rescue URI::InvalidURIError
  Logger.new($stderr).fatal("invalid URI in database connection string")
  exit 1
end

hathifiles = HathifilesDatabase::Hathifiles.new(
  hathifiles_directory: ENV["HATHIFILES_DIR"],
  connection: connection
)

tracker = PushMetrics.new(
  # batch_size could be put in ENV but care would have to be taken with the integer conversion.
  batch_size: 10_000,
  job_name: ENV.fetch("HATHIFILES_DATABASE_JOB_NAME", "hathifiles_database"),
  logger: connection.logger
)

Dir.mktmpdir do |tempdir|
  # `missing_full_hathifiles` returns an Array with zero or one element
  # since only the most recent monthly file (if any) is of interest.
  #
  # We always process the full file first, then any updates.
  # Whether or not this is strictly necessary (the update released
  # on the same day as the full file may be superfluous), this is how
  # `hathitrust_catalog_indexer` does it.
  connection.logger.info "full hathifiles: #{hathifiles.missing_full_hathifiles}"
  if hathifiles.missing_full_hathifiles.any?
    hathifile = File.join(ENV["HATHIFILES_DIR"], hathifiles.missing_full_hathifiles.first)
    connection.logger.info "processing monthly #{hathifile}"
    HathifilesDatabase::MonthlyUpdate.new(
      connection: connection,
      hathifile: hathifile,
      output_directory: tempdir
    ).run do |records_inserted|
      tracker.increment records_inserted
      tracker.on_batch { |_t| connection.logger.info tracker.batch_line }
    end
  end
  connection.logger.info "updates: #{hathifiles.missing_update_hathifiles}"
  hathifiles.missing_update_hathifiles.each do |hathifile|
    hathifile = File.join(ENV["HATHIFILES_DIR"], hathifile)
    connection.logger.info "processing update #{hathifile}"
    connection.update_from_file(hathifile) do |records_inserted|
      tracker.increment records_inserted
      tracker.on_batch { |_t| connection.logger.info tracker.batch_line }
    end
  end
end
tracker.log_final_line
